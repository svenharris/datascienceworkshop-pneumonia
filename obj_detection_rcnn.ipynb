{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckEnvironment.ipynb\t    kernel.ipynb\t      Pneumonia_Training.ipynb\r\n",
      "config.py\t\t    kernel_LG.ipynb\t      __pycache__\r\n",
      "create_patient_JSONs.ipynb  logs\t\t      README.md\r\n",
      "data\t\t\t    models\t\t      req.txt\r\n",
      "data_preprocessing\t    obj_detection_rcnn.ipynb  resources\r\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from keras_rcnn import datasets, models, preprocessing, utils\n",
    "from keras_rcnn.datasets import shape\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'data'\n",
    "JSON_FILE = os.path.join(DATA_PATH,r'train_positive.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': {'checksum': '14a05c5cd4498a9beb3bc9ca555c8cd0',\n",
       "  'pathname': 'data/train_images/positive/4525bf0b-20b4-4f4f-9149-e32632812d89.png',\n",
       "  'shape': {'r': 1024, 'c': 1024, 'channels': 1}},\n",
       " 'objects': [{'bounding_box': {'minimum': {'r': 301, 'c': 403},\n",
       "    'maximum': {'r': 491, 'c': 757}},\n",
       "   'category': 'sick'},\n",
       "  {'bounding_box': {'minimum': {'r': 533, 'c': 359},\n",
       "    'maximum': {'r': 788, 'c': 755}},\n",
       "   'category': 'sick'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "\n",
    "with open(JSON_FILE) as j:\n",
    "    data = json.load(j)\n",
    "    \n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4527"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shuffled = data[:]\n",
    "\n",
    "portion = int(0.8*len(data_shuffled))\n",
    "\n",
    "#shufflee  list\n",
    "random.seed(55)\n",
    "random.shuffle(data_shuffled)\n",
    "\n",
    "training_dictionary = data_shuffled[:20]\n",
    "test_dictionary = data_shuffled[20:30]\n",
    "\n",
    "portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\"sick\": 1}\n",
    "\n",
    "generator = preprocessing.ObjectDetectionGenerator()\n",
    "\n",
    "generator = generator.flow_from_dictionary(\n",
    "    dictionary=training_dictionary,\n",
    "    categories=categories,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "validation_data = preprocessing.ObjectDetectionGenerator()\n",
    "\n",
    "validation_data = validation_data.flow_from_dictionary(\n",
    "    dictionary=test_dictionary,\n",
    "    categories=categories,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "target,_ = generator.next()\n",
    "\n",
    "target_bounding_boxes, target_categories, target_images, target_masks, target_metadata = target\n",
    "\n",
    "target_bounding_boxes = numpy.squeeze(target_bounding_boxes)\n",
    "\n",
    "target_images = numpy.squeeze(target_images)\n",
    "\n",
    "target_categories = numpy.argmax(target_categories, -1)\n",
    "\n",
    "target_categories = numpy.squeeze(target_categories)\n",
    "\n",
    "if(len(target_bounding_boxes.shape) != 2):\n",
    "    target_bounding_boxes = numpy.array([target_bounding_boxes])\n",
    "print(target_bounding_boxes.shape)\n",
    "utils.show_bounding_boxes(target_images, target_bounding_boxes, target_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_rcnn.\n",
    "model = models.RCNN((224, 224, 3), [\"pneumonia\"])\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, TerminateOnNaN, TensorBoard, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "history = LossHistory()\n",
    "\n",
    "term_nan = TerminateOnNaN()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateLR(i, lr):\n",
    "    if (i == 0):\n",
    "        return 0.001\n",
    "    elif(i < 10):\n",
    "        return lr*0.9\n",
    "    elif(i < 20):\n",
    "        return lr*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=16, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None)\n",
    "sche = LearningRateScheduler(schedule=UpdateLR, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/Documents/venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/Documents/venv/lib/python3.6/site-packages/scikit_image-0.14.0-py3.6-linux-x86_64.egg/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/home/claudio/Documents/venv/lib/python3.6/site-packages/scikit_image-0.14.0-py3.6-linux-x86_64.egg/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/claudio/Documents/venv/lib/python3.6/site-packages/scikit_image-0.14.0-py3.6-linux-x86_64.egg/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "20/20 [==============================] - 39s 2s/step - loss: 90.2694 - val_loss: 634578.3451\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
      "20/20 [==============================] - 38s 2s/step - loss: 2.3799 - val_loss: 736046.4193\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0008100000384729356.\n",
      "20/20 [==============================] - 38s 2s/step - loss: 1.6441 - val_loss: 206642.0176\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0007290000503417104.\n",
      "12/20 [=================>............] - ETA: 13s - loss: 1.5560"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    epochs=10,\n",
    "    generator=generator,\n",
    "    validation_data=validation_data,\n",
    "    callbacks=[history,term_nan,tb,sche]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "image = skimage.io.imread(r'data/test_images/00a05408-8291-4231-886e-13763e103161.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsna",
   "language": "python",
   "name": "rsna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
