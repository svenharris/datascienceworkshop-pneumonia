{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia_Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* v001_Initial commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import itertools\n",
    "from scipy import misc\n",
    "\n",
    "# keras\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.preprocessing import image\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Google Drive/Colab Notebooks/features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-960ea39d8c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mCLF_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D:/Google Drive/Colab Notebooks/features/clf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_FEATURES_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Google Drive/Colab Notebooks/features'"
     ]
    }
   ],
   "source": [
    "# DATA_DIR = os.path.join(os.path.expandvars('%HOMEPATH%'), 'Downloads/Data')\n",
    "DATA_DIR = os.path.join('data')\n",
    "\n",
    "TRAIN_DCM = os.path.join(DATA_DIR, \"stage_1_train_images\")\n",
    "TEST_DCM = os.path.join(DATA_DIR, \"stage_1_test_images\")\n",
    "TRAIN_IMAGES = os.path.join(DATA_DIR, \"train_images\")\n",
    "TEST_IMAGES = os.path.join(DATA_DIR, \"test_images\")\n",
    "TRAIN_IMAGES_POSITIVE = os.path.join(TRAIN_IMAGES, 'positive')\n",
    "TRAIN_IMAGES_NEGATIVE = os.path.join(TRAIN_IMAGES, 'negative')\n",
    "\n",
    "TRAIN_FEATURES_DIR = 'D:/Google Drive/Colab Notebooks/features'# os.path.join(TRAIN_IMAGES, 'features')\n",
    "CLF_DIR = 'D:/Google Drive/Colab Notebooks/features/clf'\n",
    "\n",
    "os.listdir(TRAIN_FEATURES_DIR)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import                VGG16\n",
    "from keras.applications.vgg19 import                VGG19\n",
    "from keras.applications.resnet50 import             ResNet50\n",
    "from keras.applications.xception import             Xception\n",
    "from keras.applications.inception_resnet_v2 import  InceptionResNetV2\n",
    "from keras.applications.inception_v3 import         InceptionV3\n",
    "from keras.applications.mobilenet import            MobileNet\n",
    "from keras.applications.mobilenetv2 import          MobileNetV2\n",
    "from keras.applications.densenet import             DenseNet121\n",
    "from keras.applications.densenet import             DenseNet169\n",
    "from keras.applications.densenet import             DenseNet201\n",
    "from keras.applications.nasnet import               NASNetLarge\n",
    "from keras.applications.nasnet import               NASNetMobile\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "class Model(object):\n",
    "\n",
    "    def __init__(self, name, architecture, input_size, include_top, pooling):\n",
    "        self.Name = name\n",
    "        self.Architecture = architecture\n",
    "        self.Input_size = input_size\n",
    "        self.Include_top = include_top\n",
    "        self.Pooling = pooling\n",
    "        self.Model = None\n",
    "\n",
    "    def CreateModel(self):\n",
    "        self.Model = self.Architecture(weights='imagenet', include_top=self.Include_top, pooling=self.Pooling)\n",
    "\n",
    "\n",
    "architectures = {\n",
    "    \"VGG16\":VGG16,\n",
    "#     \"VGG19\":VGG19,\n",
    "#     \"ResNet50\":ResNet50,\n",
    "#     \"Xception\":Xception,\n",
    "#     \"InceptionResNetV2\":InceptionResNetV2,\n",
    "#     \"InceptionV3\":InceptionV3,\n",
    "#     # \"MobileNet\":MobileNet,\n",
    "#     \"MobileNetV2\":MobileNetV2,\n",
    "#     \"DenseNet121\":DenseNet121,\n",
    "#     # \"DenseNet169\":DenseNet169,\n",
    "#     \"DenseNet201\":DenseNet201,\n",
    "#     \"NASNetLarge\":NASNetLarge,\n",
    "    # \"NASNetMobile\":NASNetMobile\n",
    "}\n",
    "\n",
    "input_size = {\n",
    "    \"VGG16\":(224,224),\n",
    "    \"VGG19\":(224,224),\n",
    "    \"ResNet50\":(224,224),\n",
    "    \"Xception\":(299,299),\n",
    "    \"InceptionResNetV2\":(299,299),\n",
    "    \"InceptionV3\":(299,299),\n",
    "    # \"MobileNet\":(224,224),\n",
    "    \"MobileNetV2\":(224,224),\n",
    "    \"DenseNet121\":(224,224),\n",
    "    # \"DenseNet169\":(224,224),\n",
    "    \"DenseNet201\":(224,224),\n",
    "    \"NASNetLarge\":(331,331),\n",
    "    # \"NASNetMobile\":(224,224)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "VGG16(include_top=False, input_shape=(224,224,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcm2np(dcm_path, target_size=(224, 224)):\n",
    "    \"\"\" Transforms a dcm into a np.array\n",
    "    \"\"\"\n",
    "    # --- Open DICOM file\n",
    "    d = pydicom.read_file(dcm_path)\n",
    "    im = d.pixel_array\n",
    "\n",
    "    # --- Convert from single-channel grayscale to 3-channel RGB\n",
    "    im = np.stack([im] * 3, axis=2)\n",
    "    \n",
    "    im = scipy.misc.imresize(im, target_size, interp='bilinear', mode=None)\n",
    "    \n",
    "    return im\n",
    "\n",
    "def _collect_models():\n",
    "    models = {}\n",
    "    for key,value in architectures.items() :\n",
    "        models[key] = Model(key, value, input_size[key], False, 'max')\n",
    "    return models\n",
    "\n",
    "\n",
    "def _generate_model(models):\n",
    "    for key,value in models.items():\n",
    "        #pos features\n",
    "        pos_df = _create_pretrained_feature_df(os.path.join(TRAIN_IMAGES, \"positive\"), \n",
    "                                               value, \n",
    "                                               partition=1.0,\n",
    "                                               target_size=input_size[key])\n",
    "\n",
    "        #neg features\n",
    "        neg_df = _create_pretrained_feature_df(os.path.join(TRAIN_IMAGES, \"negative\"), \n",
    "                                               value, \n",
    "                                               partition=0.25,\n",
    "                                               target_size=input_size[key])\n",
    "        \n",
    "        del value.Model\n",
    "\n",
    "def _get_feature_values(img_path, model, target_size):\n",
    "    \"\"\" Get the feature values for a specific image out of pre-trained model \n",
    "    \"\"\"\n",
    "#     img = dcm2np(img_path)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    print(x.shape)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    print(x.shape)\n",
    "    x = preprocess_input(x)\n",
    "    print(x.shape)\n",
    "    raise Exception()\n",
    "    return model.predict(x)[0].reshape(-1)\n",
    "\n",
    "def _create_pretrained_feature_df(class_directory, model, partition=1.0, target_size=(224, 224)):\n",
    "    \"\"\" Create features dataframe based on pretrained model \n",
    "    \"\"\"\n",
    "\n",
    "    features = []\n",
    "    patientId = []\n",
    "    \n",
    "    #instantiate model\n",
    "    model.CreateModel()\n",
    "    m = model.Model\n",
    "    \n",
    "    print('')\n",
    "    print('    ***')\n",
    "    print('Inference for {0} {1}'.format(class_directory, model.Name))\n",
    "    print('')\n",
    "    \n",
    "    path = os.path.normpath(class_directory)    \n",
    "    csv_saveto = path.split(os.sep)[-1]\n",
    "\n",
    "\n",
    "    def enumImgPath(class_directory,partition):\n",
    "        max = len(os.listdir(class_directory))\n",
    "        i=0\n",
    "        for n, file in enumerate(os.listdir(class_directory)):\n",
    "            if i > int(max*partition):\n",
    "                break\n",
    "            i+=1\n",
    "            yield file\n",
    "            \n",
    "    divisor = 50\n",
    "    n_max = len(os.listdir(class_directory))\n",
    "   \n",
    "    for n, file in enumerate(enumImgPath(class_directory,partition)):\n",
    "        full_path = os.path.join(class_directory, file)\n",
    "        features.append(_get_feature_values(full_path, m,target_size=target_size))\n",
    "        patientId.append(file)\n",
    "        \n",
    "        csv_path = os.path.join(TRAIN_FEATURES_DIR,csv_saveto,'{0}_{1:05d}.csv'.format(model.Name,n))\n",
    "        \n",
    "        if( (n+1) % (n_max/divisor) ==0 ):\n",
    "            print('Scoring image {0}'.format(n/n_max))\n",
    "            df = pd.DataFrame(np.stack(features))\n",
    "            df['patientID'] = patientId\n",
    "            df.to_csv(path_or_buf=csv_path)\n",
    "            print('Saved file {0}'.format(csv_path))\n",
    "            features = []\n",
    "\n",
    "    df = pd.DataFrame(np.stack(features))\n",
    "    df['patientID'] = patientId\n",
    "    df.to_csv(path_or_buf=csv_path)\n",
    "    print('Saved file {0}'.format(csv_path))\n",
    "            \n",
    "    return pd.DataFrame(np.stack(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ***\n",
      "Inference for data/train_images/positive VGG16\n",
      "\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-4618152cf2eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collect_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_generate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-759d8910d9b4>\u001b[0m in \u001b[0;36m_generate_model\u001b[0;34m(models)\u001b[0m\n\u001b[1;32m     26\u001b[0m                                                \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                                \u001b[0mpartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                                                target_size=input_size[key])\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#neg features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-759d8910d9b4>\u001b[0m in \u001b[0;36m_create_pretrained_feature_df\u001b[0;34m(class_directory, model, partition, target_size)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumImgPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mfull_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_feature_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mpatientId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-759d8910d9b4>\u001b[0m in \u001b[0;36m_get_feature_values\u001b[0;34m(img_path, model, target_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = _collect_models()\n",
    "_generate_model(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Nearest Neighbors\":KNeighborsClassifier(3),\n",
    "    \"Linear SVM\":SVC(kernel=\"linear\", C=0.025, probability=True),\n",
    "    \"RBF SVM\":SVC(gamma=2, C=1, probability=True),\n",
    "    \"Gaussian Process\":GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    \"Decision Tree\":DecisionTreeClassifier(max_depth=5),\n",
    "    \"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    \"Neural Net\":MLPClassifier(alpha=1),\n",
    "    \"AdaBoost\":AdaBoostClassifier(),\n",
    "    \"Naive Bayes\":GaussianNB(),\n",
    "    \"QDA\":QuadraticDiscriminantAnalysis()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf', 'negative', 'positive']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(TRAIN_FEATURES_DIR)[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "subset = 100000\n",
    "\n",
    "metadata = pd.read_csv(os.path.join(TRAIN_IMAGES, 'metadata.csv'))\n",
    "metadata = metadata[['patient_id', 'patients_age']]\n",
    "df_neg = pd.DataFrame({'patientId': [os.path.splitext(f)[0] for f in os.listdir(TRAIN_IMAGES_NEGATIVE)[:subset]]})\n",
    "df_pos = pd.DataFrame({'patientId': [os.path.splitext(f)[0] for f in os.listdir(TRAIN_IMAGES_POSITIVE)[:subset]]})\n",
    "\n",
    "names = []\n",
    "for _df in (df_neg, df_pos):\n",
    "    for i, row in _df.iterrows():\n",
    "        r = metadata.loc[metadata['patient_id'] == row['patientId']]\n",
    "        if len(r) == 0:\n",
    "            names.append(row['patientId'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_df = df_neg = pd.DataFrame({'patientId': [os.path.splitext(f)[0] for f in os.listdir(TRAIN_IMAGES_NEGATIVE)]})\n",
    "_df = pd.concat([_df, pd.DataFrame({'patientId': [os.path.splitext(f)[0] for f in os.listdir(TRAIN_IMAGES_POSITIVE)]})])\n",
    "\n",
    "metadatas = []\n",
    "\n",
    "for i, row in _df.iterrows():\n",
    "    # --- Open DICOM file\n",
    "    dcm_path = os.path.join(TRAIN_DCM, row['patientId']) + '.dcm'\n",
    "    dcm_file = pydicom.read_file(dcm_path)\n",
    "    raw_dict = {x.description(): x.value for x in dcm_file.iterall() if x.description() != \"Pixel Data\"}\n",
    "    for key in raw_dict.keys():\n",
    "        new_key = key.replace(\"'\", \"\").replace(\" \", \"_\").lower()\n",
    "        raw_dict[new_key] = raw_dict.pop(key)\n",
    "    \n",
    "    metadatas.append(raw_dict)\n",
    "    \n",
    "df = pd.DataFrame(metadatas)\n",
    "df.to_csv(os.path.join(DATA_DIR, 'metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReadFeatureModel(name):\n",
    "\n",
    "    subset = 5000\n",
    "    print(f'subset: {subset}')\n",
    "    \n",
    "    # read negative/positive\n",
    "    df_positive = pd.read_csv(os.path.join(TRAIN_FEATURES_DIR, 'positive', f'{name}_05658.csv'), index_col=0)\n",
    "    df_negative = pd.read_csv(os.path.join(TRAIN_FEATURES_DIR, 'negative', f'{name}_05006.csv'), index_col=0)\n",
    "    df_negative = df_negative.iloc[:len(df_positive)]\n",
    "\n",
    "    df_positive = df_positive.iloc[:subset]\n",
    "    df_negative = df_negative.iloc[:subset]\n",
    "\n",
    "    df_positive['Target'] = 1\n",
    "    df_negative['Target'] = 0\n",
    "\n",
    "    df_positive['patientId'] = [os.path.splitext(f)[0] for f in os.listdir(TRAIN_IMAGES_POSITIVE)[:subset]]\n",
    "    df_negative['patientId'] = [os.path.splitext(f)[0] for f in os.listdir(TRAIN_IMAGES_NEGATIVE)[:subset]]\n",
    "\n",
    "    # append metadata to negative/positive\n",
    "    if(False):\n",
    "        metadata = pd.read_csv(os.path.join(TRAIN_IMAGES, 'metadata.csv'))\n",
    "        metadata = metadata[['patient_id', 'patients_age']]\n",
    "        df_neg = pd.DataFrame({'patientId': [os.path.splitext(f)[0] for f in os.listdir(TRAIN_IMAGES_NEGATIVE)[:subset]]})\n",
    "        df_pos = pd.DataFrame({'patientId': [os.path.splitext(f)[0] for f in os.listdir(TRAIN_IMAGES_POSITIVE)[:subset]]})\n",
    "\n",
    "        for _df in (df_neg, df_pos):\n",
    "            ages = []\n",
    "            for i, row in _df.iterrows():\n",
    "                r = metadata.loc[metadata['patient_id'] == row['patientId']]\n",
    "                ages.append(r['patients_age'].values[0])\n",
    "\n",
    "            _df['age'] = ages\n",
    "\n",
    "        df_positive['age'] = df_pos['age']\n",
    "        df_negative['age'] = df_neg['age']\n",
    "    elif(False):\n",
    "        for _df in (df_positive, df_negative):\n",
    "            ages = []\n",
    "            for i, row in _df.iterrows():\n",
    "                # --- Open DICOM file\n",
    "                dcm_path = os.path.join(TRAIN_DCM, row['patientId']) + '.dcm'\n",
    "                d = pydicom.read_file(dcm_path)\n",
    "\n",
    "                ages.append(d.PatientAge)\n",
    "\n",
    "            _df['age'] = ages\n",
    "    else:\n",
    "        metadata = pd.read_csv(os.path.join(DATA_DIR, 'metadata.csv'))\n",
    "        metadata = metadata[['Patient ID', 'Patient\\'s Age']]\n",
    "        df_neg = pd.DataFrame({'patientId': [os.path.splitext(f)[0] for f in os.listdir(TRAIN_IMAGES_NEGATIVE)[:subset]]})\n",
    "        df_pos = pd.DataFrame({'patientId': [os.path.splitext(f)[0] for f in os.listdir(TRAIN_IMAGES_POSITIVE)[:subset]]})\n",
    "\n",
    "        for _df in (df_neg, df_pos):\n",
    "            ages = []\n",
    "            for i, row in _df.iterrows():\n",
    "                r = metadata.loc[metadata['Patient ID'] == row['patientId']]\n",
    "                ages.append(r['Patient\\'s Age'].values[0])\n",
    "\n",
    "            _df['age'] = ages\n",
    "\n",
    "        df_positive['age'] = df_pos['age']\n",
    "        df_negative['age'] = df_neg['age']\n",
    "\n",
    "    # concatenate the two datasets\n",
    "    df = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    return df\n",
    "\n",
    "#     df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "im_gen = ImageDataGenerator(\n",
    "                            featurewise_center=False, \n",
    "                            samplewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            samplewise_std_normalization=False, \n",
    "                            zca_whitening=False, \n",
    "                            zca_epsilon=1e-06, \n",
    "                            rotation_range=0, \n",
    "                            width_shift_range=0.1, \n",
    "                            height_shift_range=0.1, \n",
    "                            brightness_range=None, \n",
    "                            shear_range=0.0, \n",
    "                            zoom_range=0.1, \n",
    "                            channel_shift_range=0.0, \n",
    "                            fill_mode='nearest', \n",
    "                            cval=0.0, \n",
    "                            horizontal_flip=False, \n",
    "                            vertical_flip=False, \n",
    "                            rescale=None, \n",
    "                            preprocessing_function=None, \n",
    "                            data_format=None, \n",
    "                            validation_split=0.0\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = im_gen.flow_from_directory(directory=r'data/train_images', color_mode='grayscale', target_size=(224,224),shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in it:\n",
    "x,y = it.next()\n",
    "x_ = x.copy()\n",
    "x_.resize((1,224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93.      ],\n",
       "       [ 93.      ],\n",
       "       [ 93.      ],\n",
       "       [ 93.      ],\n",
       "       [ 93.      ],\n",
       "       [ 88.96095 ],\n",
       "       [ 80.211586],\n",
       "       [ 77.81098 ],\n",
       "       [ 76.76953 ],\n",
       "       [ 74.95855 ],\n",
       "       [ 74.03233 ],\n",
       "       [ 74.      ],\n",
       "       [ 73.1799  ],\n",
       "       [ 73.746315],\n",
       "       [ 70.63733 ],\n",
       "       [ 69.      ],\n",
       "       [ 66.90014 ],\n",
       "       [ 64.54882 ],\n",
       "       [ 63.6226  ],\n",
       "       [ 63.303616],\n",
       "       [ 63.31051 ],\n",
       "       [ 60.843952],\n",
       "       [ 59.835472],\n",
       "       [ 57.99152 ],\n",
       "       [ 57.065304],\n",
       "       [ 55.278175],\n",
       "       [ 55.      ],\n",
       "       [ 58.566723],\n",
       "       [ 68.95385 ],\n",
       "       [ 79.091995],\n",
       "       [ 85.45997 ],\n",
       "       [ 87.16358 ],\n",
       "       [ 85.31115 ],\n",
       "       [ 82.64679 ],\n",
       "       [ 78.409424],\n",
       "       [ 75.5077  ],\n",
       "       [ 71.90142 ],\n",
       "       [ 70.04899 ],\n",
       "       [ 69.098274],\n",
       "       [ 69.      ],\n",
       "       [ 69.      ],\n",
       "       [ 68.319626],\n",
       "       [ 64.96706 ],\n",
       "       [ 62.467194],\n",
       "       [ 62.459023],\n",
       "       [ 63.38524 ],\n",
       "       [ 64.62291 ],\n",
       "       [ 66.47534 ],\n",
       "       [ 69.1472  ],\n",
       "       [ 75.27031 ],\n",
       "       [ 78.09791 ],\n",
       "       [ 83.655205],\n",
       "       [ 89.2125  ],\n",
       "       [ 93.17987 ],\n",
       "       [ 97.60592 ],\n",
       "       [102.8844  ],\n",
       "       [105.573616],\n",
       "       [108.49916 ],\n",
       "       [111.      ],\n",
       "       [112.05679 ],\n",
       "       [114.83544 ],\n",
       "       [117.      ],\n",
       "       [117.261826],\n",
       "       [118.94287 ],\n",
       "       [118.016655],\n",
       "       [120.72868 ],\n",
       "       [121.83578 ],\n",
       "       [123.52399 ],\n",
       "       [126.06463 ],\n",
       "       [128.84328 ],\n",
       "       [130.      ],\n",
       "       [130.      ],\n",
       "       [131.5723  ],\n",
       "       [134.31929 ],\n",
       "       [135.      ],\n",
       "       [135.51517 ],\n",
       "       [138.19588 ],\n",
       "       [140.04831 ],\n",
       "       [141.90074 ],\n",
       "       [142.87659 ],\n",
       "       [144.6056  ],\n",
       "       [146.45804 ],\n",
       "       [148.96571 ],\n",
       "       [151.1629  ],\n",
       "       [155.5537  ],\n",
       "       [165.07442 ],\n",
       "       [174.0803  ],\n",
       "       [176.85896 ],\n",
       "       [179.21254 ],\n",
       "       [180.69376 ],\n",
       "       [185.3898  ],\n",
       "       [190.9471  ],\n",
       "       [194.6696  ],\n",
       "       [197.53085 ],\n",
       "       [198.      ],\n",
       "       [198.69604 ],\n",
       "       [200.24454 ],\n",
       "       [201.      ],\n",
       "       [201.9494  ],\n",
       "       [203.40091 ],\n",
       "       [204.      ],\n",
       "       [204.5067  ],\n",
       "       [206.35913 ],\n",
       "       [207.89423 ],\n",
       "       [207.096   ],\n",
       "       [209.87463 ],\n",
       "       [210.88443 ],\n",
       "       [211.81064 ],\n",
       "       [212.73686 ],\n",
       "       [214.32616 ],\n",
       "       [215.      ],\n",
       "       [214.4845  ],\n",
       "       [215.7669  ],\n",
       "       [217.26411 ],\n",
       "       [217.17664 ],\n",
       "       [220.44075 ],\n",
       "       [222.      ],\n",
       "       [222.21841 ],\n",
       "       [224.99707 ],\n",
       "       [226.85048 ],\n",
       "       [225.29709 ],\n",
       "       [225.      ],\n",
       "       [222.88834 ],\n",
       "       [224.52042 ],\n",
       "       [226.55632 ],\n",
       "       [225.06985 ],\n",
       "       [222.59125 ],\n",
       "       [222.      ],\n",
       "       [222.      ],\n",
       "       [222.18741 ],\n",
       "       [223.11362 ],\n",
       "       [224.03984 ],\n",
       "       [224.96605 ],\n",
       "       [225.      ],\n",
       "       [224.18152 ],\n",
       "       [226.2341  ],\n",
       "       [228.34183 ],\n",
       "       [229.      ],\n",
       "       [227.95331 ],\n",
       "       [227.44957 ],\n",
       "       [227.62422 ],\n",
       "       [226.698   ],\n",
       "       [226.45642 ],\n",
       "       [227.84557 ],\n",
       "       [226.91936 ],\n",
       "       [226.00687 ],\n",
       "       [226.93307 ],\n",
       "       [227.8593  ],\n",
       "       [227.2145  ],\n",
       "       [226.28827 ],\n",
       "       [226.63794 ],\n",
       "       [227.      ],\n",
       "       [226.50963 ],\n",
       "       [226.      ],\n",
       "       [226.      ],\n",
       "       [226.      ],\n",
       "       [226.      ],\n",
       "       [225.87854 ],\n",
       "       [225.04767 ],\n",
       "       [225.97389 ],\n",
       "       [226.      ],\n",
       "       [225.17368 ],\n",
       "       [226.50508 ],\n",
       "       [226.32124 ],\n",
       "       [225.39503 ],\n",
       "       [224.46881 ],\n",
       "       [224.      ],\n",
       "       [223.23276 ],\n",
       "       [221.38033 ],\n",
       "       [219.76395 ],\n",
       "       [219.      ],\n",
       "       [218.82303 ],\n",
       "       [216.9559  ],\n",
       "       [214.17725 ],\n",
       "       [214.      ],\n",
       "       [212.4133  ],\n",
       "       [212.71956 ],\n",
       "       [213.      ],\n",
       "       [213.      ],\n",
       "       [212.50179 ],\n",
       "       [211.57558 ],\n",
       "       [210.2987  ],\n",
       "       [208.44627 ],\n",
       "       [206.79692 ],\n",
       "       [205.87071 ],\n",
       "       [193.6203  ],\n",
       "       [  3.745978],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ],\n",
       "       [  0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93.      ,  93.      ,  93.      ],\n",
       "       [ 93.      ,  93.      ,  88.96095 ],\n",
       "       [ 80.211586,  77.81098 ,  76.76953 ],\n",
       "       [ 74.95855 ,  74.03233 ,  74.      ],\n",
       "       [ 73.1799  ,  73.746315,  70.63733 ],\n",
       "       [ 69.      ,  66.90014 ,  64.54882 ],\n",
       "       [ 63.6226  ,  63.303616,  63.31051 ],\n",
       "       [ 60.843952,  59.835472,  57.99152 ],\n",
       "       [ 57.065304,  55.278175,  55.      ],\n",
       "       [ 58.566723,  68.95385 ,  79.091995],\n",
       "       [ 85.45997 ,  87.16358 ,  85.31115 ],\n",
       "       [ 82.64679 ,  78.409424,  75.5077  ],\n",
       "       [ 71.90142 ,  70.04899 ,  69.098274],\n",
       "       [ 69.      ,  69.      ,  68.319626],\n",
       "       [ 64.96706 ,  62.467194,  62.459023],\n",
       "       [ 63.38524 ,  64.62291 ,  66.47534 ],\n",
       "       [ 69.1472  ,  75.27031 ,  78.09791 ],\n",
       "       [ 83.655205,  89.2125  ,  93.17987 ],\n",
       "       [ 97.60592 , 102.8844  , 105.573616],\n",
       "       [108.49916 , 111.      , 112.05679 ],\n",
       "       [114.83544 , 117.      , 117.261826],\n",
       "       [118.94287 , 118.016655, 120.72868 ],\n",
       "       [121.83578 , 123.52399 , 126.06463 ],\n",
       "       [128.84328 , 130.      , 130.      ],\n",
       "       [131.5723  , 134.31929 , 135.      ],\n",
       "       [135.51517 , 138.19588 , 140.04831 ],\n",
       "       [141.90074 , 142.87659 , 144.6056  ],\n",
       "       [146.45804 , 148.96571 , 151.1629  ],\n",
       "       [155.5537  , 165.07442 , 174.0803  ],\n",
       "       [176.85896 , 179.21254 , 180.69376 ],\n",
       "       [185.3898  , 190.9471  , 194.6696  ],\n",
       "       [197.53085 , 198.      , 198.69604 ],\n",
       "       [200.24454 , 201.      , 201.9494  ],\n",
       "       [203.40091 , 204.      , 204.5067  ],\n",
       "       [206.35913 , 207.89423 , 207.096   ],\n",
       "       [209.87463 , 210.88443 , 211.81064 ],\n",
       "       [212.73686 , 214.32616 , 215.      ],\n",
       "       [214.4845  , 215.7669  , 217.26411 ],\n",
       "       [217.17664 , 220.44075 , 222.      ],\n",
       "       [222.21841 , 224.99707 , 226.85048 ],\n",
       "       [225.29709 , 225.      , 222.88834 ],\n",
       "       [224.52042 , 226.55632 , 225.06985 ],\n",
       "       [222.59125 , 222.      , 222.      ],\n",
       "       [222.18741 , 223.11362 , 224.03984 ],\n",
       "       [224.96605 , 225.      , 224.18152 ],\n",
       "       [226.2341  , 228.34183 , 229.      ],\n",
       "       [227.95331 , 227.44957 , 227.62422 ],\n",
       "       [226.698   , 226.45642 , 227.84557 ],\n",
       "       [226.91936 , 226.00687 , 226.93307 ],\n",
       "       [227.8593  , 227.2145  , 226.28827 ],\n",
       "       [226.63794 , 227.      , 226.50963 ],\n",
       "       [226.      , 226.      , 226.      ],\n",
       "       [226.      , 225.87854 , 225.04767 ],\n",
       "       [225.97389 , 226.      , 225.17368 ],\n",
       "       [226.50508 , 226.32124 , 225.39503 ],\n",
       "       [224.46881 , 224.      , 223.23276 ],\n",
       "       [221.38033 , 219.76395 , 219.      ],\n",
       "       [218.82303 , 216.9559  , 214.17725 ],\n",
       "       [214.      , 212.4133  , 212.71956 ],\n",
       "       [213.      , 213.      , 212.50179 ],\n",
       "       [211.57558 , 210.2987  , 208.44627 ],\n",
       "       [206.79692 , 205.87071 , 193.6203  ],\n",
       "       [  3.745978,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,  93.      ],\n",
       "       [ 93.      ,  93.      ,  93.      ],\n",
       "       [ 93.      ,  88.96095 ,  80.211586],\n",
       "       [ 77.81098 ,  76.76953 ,  74.95855 ],\n",
       "       [ 74.03233 ,  74.      ,  73.1799  ],\n",
       "       [ 73.746315,  70.63733 ,  69.      ],\n",
       "       [ 66.90014 ,  64.54882 ,  63.6226  ],\n",
       "       [ 63.303616,  63.31051 ,  60.843952],\n",
       "       [ 59.835472,  57.99152 ,  57.065304],\n",
       "       [ 55.278175,  55.      ,  58.566723],\n",
       "       [ 68.95385 ,  79.091995,  85.45997 ],\n",
       "       [ 87.16358 ,  85.31115 ,  82.64679 ],\n",
       "       [ 78.409424,  75.5077  ,  71.90142 ],\n",
       "       [ 70.04899 ,  69.098274,  69.      ],\n",
       "       [ 69.      ,  68.319626,  64.96706 ],\n",
       "       [ 62.467194,  62.459023,  63.38524 ],\n",
       "       [ 64.62291 ,  66.47534 ,  69.1472  ],\n",
       "       [ 75.27031 ,  78.09791 ,  83.655205],\n",
       "       [ 89.2125  ,  93.17987 ,  97.60592 ],\n",
       "       [102.8844  , 105.573616, 108.49916 ],\n",
       "       [111.      , 112.05679 , 114.83544 ],\n",
       "       [117.      , 117.261826, 118.94287 ],\n",
       "       [118.016655, 120.72868 , 121.83578 ],\n",
       "       [123.52399 , 126.06463 , 128.84328 ],\n",
       "       [130.      , 130.      , 131.5723  ],\n",
       "       [134.31929 , 135.      , 135.51517 ],\n",
       "       [138.19588 , 140.04831 , 141.90074 ],\n",
       "       [142.87659 , 144.6056  , 146.45804 ],\n",
       "       [148.96571 , 151.1629  , 155.5537  ],\n",
       "       [165.07442 , 174.0803  , 176.85896 ],\n",
       "       [179.21254 , 180.69376 , 185.3898  ],\n",
       "       [190.9471  , 194.6696  , 197.53085 ],\n",
       "       [198.      , 198.69604 , 200.24454 ],\n",
       "       [201.      , 201.9494  , 203.40091 ],\n",
       "       [204.      , 204.5067  , 206.35913 ],\n",
       "       [207.89423 , 207.096   , 209.87463 ],\n",
       "       [210.88443 , 211.81064 , 212.73686 ],\n",
       "       [214.32616 , 215.      , 214.4845  ],\n",
       "       [215.7669  , 217.26411 , 217.17664 ],\n",
       "       [220.44075 , 222.      , 222.21841 ],\n",
       "       [224.99707 , 226.85048 , 225.29709 ],\n",
       "       [225.      , 222.88834 , 224.52042 ],\n",
       "       [226.55632 , 225.06985 , 222.59125 ],\n",
       "       [222.      , 222.      , 222.18741 ],\n",
       "       [223.11362 , 224.03984 , 224.96605 ],\n",
       "       [225.      , 224.18152 , 226.2341  ],\n",
       "       [228.34183 , 229.      , 227.95331 ],\n",
       "       [227.44957 , 227.62422 , 226.698   ],\n",
       "       [226.45642 , 227.84557 , 226.91936 ],\n",
       "       [226.00687 , 226.93307 , 227.8593  ],\n",
       "       [227.2145  , 226.28827 , 226.63794 ],\n",
       "       [227.      , 226.50963 , 226.      ],\n",
       "       [226.      , 226.      , 226.      ],\n",
       "       [225.87854 , 225.04767 , 225.97389 ],\n",
       "       [226.      , 225.17368 , 226.50508 ],\n",
       "       [226.32124 , 225.39503 , 224.46881 ],\n",
       "       [224.      , 223.23276 , 221.38033 ],\n",
       "       [219.76395 , 219.      , 218.82303 ],\n",
       "       [216.9559  , 214.17725 , 214.      ],\n",
       "       [212.4133  , 212.71956 , 213.      ],\n",
       "       [213.      , 212.50179 , 211.57558 ],\n",
       "       [210.2987  , 208.44627 , 206.79692 ],\n",
       "       [205.87071 , 193.6203  ,   3.745978],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,  93.      ,  93.      ],\n",
       "       [ 93.      ,  93.      ,  93.      ],\n",
       "       [ 88.96095 ,  80.211586,  77.81098 ],\n",
       "       [ 76.76953 ,  74.95855 ,  74.03233 ],\n",
       "       [ 74.      ,  73.1799  ,  73.746315],\n",
       "       [ 70.63733 ,  69.      ,  66.90014 ],\n",
       "       [ 64.54882 ,  63.6226  ,  63.303616],\n",
       "       [ 63.31051 ,  60.843952,  59.835472],\n",
       "       [ 57.99152 ,  57.065304,  55.278175],\n",
       "       [ 55.      ,  58.566723,  68.95385 ],\n",
       "       [ 79.091995,  85.45997 ,  87.16358 ],\n",
       "       [ 85.31115 ,  82.64679 ,  78.409424],\n",
       "       [ 75.5077  ,  71.90142 ,  70.04899 ],\n",
       "       [ 69.098274,  69.      ,  69.      ],\n",
       "       [ 68.319626,  64.96706 ,  62.467194],\n",
       "       [ 62.459023,  63.38524 ,  64.62291 ],\n",
       "       [ 66.47534 ,  69.1472  ,  75.27031 ],\n",
       "       [ 78.09791 ,  83.655205,  89.2125  ],\n",
       "       [ 93.17987 ,  97.60592 , 102.8844  ],\n",
       "       [105.573616, 108.49916 , 111.      ],\n",
       "       [112.05679 , 114.83544 , 117.      ],\n",
       "       [117.261826, 118.94287 , 118.016655],\n",
       "       [120.72868 , 121.83578 , 123.52399 ],\n",
       "       [126.06463 , 128.84328 , 130.      ],\n",
       "       [130.      , 131.5723  , 134.31929 ],\n",
       "       [135.      , 135.51517 , 138.19588 ],\n",
       "       [140.04831 , 141.90074 , 142.87659 ],\n",
       "       [144.6056  , 146.45804 , 148.96571 ],\n",
       "       [151.1629  , 155.5537  , 165.07442 ],\n",
       "       [174.0803  , 176.85896 , 179.21254 ],\n",
       "       [180.69376 , 185.3898  , 190.9471  ],\n",
       "       [194.6696  , 197.53085 , 198.      ],\n",
       "       [198.69604 , 200.24454 , 201.      ],\n",
       "       [201.9494  , 203.40091 , 204.      ],\n",
       "       [204.5067  , 206.35913 , 207.89423 ],\n",
       "       [207.096   , 209.87463 , 210.88443 ],\n",
       "       [211.81064 , 212.73686 , 214.32616 ],\n",
       "       [215.      , 214.4845  , 215.7669  ],\n",
       "       [217.26411 , 217.17664 , 220.44075 ],\n",
       "       [222.      , 222.21841 , 224.99707 ],\n",
       "       [226.85048 , 225.29709 , 225.      ],\n",
       "       [222.88834 , 224.52042 , 226.55632 ],\n",
       "       [225.06985 , 222.59125 , 222.      ],\n",
       "       [222.      , 222.18741 , 223.11362 ],\n",
       "       [224.03984 , 224.96605 , 225.      ],\n",
       "       [224.18152 , 226.2341  , 228.34183 ],\n",
       "       [229.      , 227.95331 , 227.44957 ],\n",
       "       [227.62422 , 226.698   , 226.45642 ],\n",
       "       [227.84557 , 226.91936 , 226.00687 ],\n",
       "       [226.93307 , 227.8593  , 227.2145  ],\n",
       "       [226.28827 , 226.63794 , 227.      ],\n",
       "       [226.50963 , 226.      , 226.      ],\n",
       "       [226.      , 226.      , 225.87854 ],\n",
       "       [225.04767 , 225.97389 , 226.      ],\n",
       "       [225.17368 , 226.50508 , 226.32124 ],\n",
       "       [225.39503 , 224.46881 , 224.      ],\n",
       "       [223.23276 , 221.38033 , 219.76395 ],\n",
       "       [219.      , 218.82303 , 216.9559  ],\n",
       "       [214.17725 , 214.      , 212.4133  ],\n",
       "       [212.71956 , 213.      , 213.      ],\n",
       "       [212.50179 , 211.57558 , 210.2987  ],\n",
       "       [208.44627 , 206.79692 , 205.87071 ],\n",
       "       [193.6203  ,   3.745978,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_.shape\n",
    "\n",
    "x_[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "x = numpy.array([x[0],x[0],x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.transpose((1, 2, 3,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 1, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_7 to have shape (1000, 224, 3) but got array with shape (224, 224, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-3a4fb3454fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                              'argument.')\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_7 to have shape (1000, 224, 3) but got array with shape (224, 224, 1)"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False, pooling='max', input_shape=(224, 224, 3))\n",
    "model.predict(x)[0].reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare feature dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PrepareDataSet(df):\n",
    "    X = df.drop(['Target', 'patientId'], axis=1)\n",
    "    Y = df['Target']\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.4, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          index=0):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    rows=3\n",
    "    ax = plt.subplot((len(classifiers) // rows) +1, rows, index+1)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Classify(X_train, X_test, y_train, y_test):\n",
    "    fig = plt.figure(figsize=(13, 13))\n",
    "\n",
    "    #X_train, X_test, y_train, y_test\n",
    "    for i, (name, clf) in enumerate(classifiers.items()):\n",
    "        print('{0} - {1}'.format(datetime.datetime.now(), name))\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        train_preds = clf.predict_proba(X_train)\n",
    "        test_preds = clf.predict_proba(X_test)\n",
    "        roc_train = roc_auc_score(y_train, train_preds[:,1])\n",
    "        roc_test = roc_auc_score(y_test, test_preds[:,1])\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "\n",
    "        plot_confusion_matrix(cnf_matrix, \n",
    "                              classes=['normal', 'recession'], \n",
    "                              normalize=True,\n",
    "                              title='{0} - {1:.3f}\\nROC train {2:.3f}, ROC test {3:.3f}'.format(name, score, roc_train, roc_test),\n",
    "                              index=i)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DenseNet121\n",
      "subset: 5000\n",
      "2018-09-18 21:37:18.153881 - Nearest Neighbors\n"
     ]
    }
   ],
   "source": [
    "for name in os.listdir(os.path.join(TRAIN_FEATURES_DIR, 'positive')):\n",
    "    name = os.path.splitext(name)[0]\n",
    "    name = name.split(sep='_')[0]\n",
    "    \n",
    "    print('--- {0}'.format(name))\n",
    "    \n",
    "    df = ReadFeatureModel(name)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = PrepareDataSet(df)\n",
    "    \n",
    "    fig = Classify(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "    # save results\n",
    "    clf_path = os.path.join(CLF_DIR, name)\n",
    "    if not os.path.exists(clf_path):\n",
    "        os.makedirs(clf_path)\n",
    "    \n",
    "    fig.savefig(os.path.join(clf_path, '{0}_benchmark.png'.format(name)))\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():        \n",
    "        joblib.dump(clf, '{0}/{1}_{2}.pkl'.format(clf_path, name, clf_name))\n",
    "    \n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame()\n",
    "\n",
    "for i, (name, clf) in enumerate(classifiers.items()):\n",
    "    print('{0} - {1}'.format(datetime.datetime.now(), name))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    train_preds = clf.predict_proba(X_train)\n",
    "    test_preds = clf.predict_proba(X_test)\n",
    "    roc_train = roc_auc_score(y_train, train_preds[:,1])\n",
    "    roc_test = roc_auc_score(y_test, test_preds[:,1])\n",
    "             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, Perceptron, PassiveAggressiveRegressor, LogisticRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV, LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "heldout = [0.95, 0.90, 0.75, 0.50, 0.01]\n",
    "rounds = 20\n",
    "\n",
    "\n",
    "    \n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0):\n",
    "        self.params = {\"objective\": \"reg:linear\", \"booster\":\"gblinear\"}\n",
    "        self.nrounds = 250\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.params, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n",
    "\n",
    "classifiers = {\n",
    "    \"PLSRegression\": PLSRegression(n_components=2),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"RidgeCV\": RidgeCV(),\n",
    "    \"MLPRegressor\": MLPRegressor(max_iter=200,hidden_layer_sizes=(50)),\n",
    "    \"KNeighborsRegressor\": KNeighborsRegressor(n_neighbors=5 ),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Object detection in short](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e)\n",
    "[Object detection more extensive](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from keras_rcnn import datasets, models, preprocessing, utils\n",
    "from keras_rcnn.datasets import shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncategories = {\"circle\": 1, \"rectangle\": 2, \"triangle\": 3}\\n\\ngenerator = preprocessing.ObjectDetectionGenerator()\\n\\ngenerator = generator.flow_from_dictionary(\\n    dictionary=training_dictionary,\\n    categories=categories,\\n    target_size=(224, 224)\\n)\\n\\nvalidation_data = preprocessing.ObjectDetectionGenerator()\\n\\nvalidation_data = validation_data.flow_from_dictionary(\\n    dictionary=test_dictionary,\\n    categories=categories,\\n    target_size=(224, 224)\\n)\\n\\ntarget, _ = generator.next()\\n\\ntarget_bounding_boxes, target_categories, target_images, target_masks, target_metadata = target\\n\\ntarget_bounding_boxes = numpy.squeeze(target_bounding_boxes)\\n\\ntarget_images = numpy.squeeze(target_images)\\n\\ntarget_categories = numpy.argmax(target_categories, -1)\\n\\ntarget_categories = numpy.squeeze(target_categories)\\n\\nutils.show_bounding_boxes(target_images, target_bounding_boxes, target_categories)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dictionary, test_dictionary = shape.load_data()\n",
    "\"\"\"\n",
    "categories = {\"circle\": 1, \"rectangle\": 2, \"triangle\": 3}\n",
    "\n",
    "generator = preprocessing.ObjectDetectionGenerator()\n",
    "\n",
    "generator = generator.flow_from_dictionary(\n",
    "    dictionary=training_dictionary,\n",
    "    categories=categories,\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "validation_data = preprocessing.ObjectDetectionGenerator()\n",
    "\n",
    "validation_data = validation_data.flow_from_dictionary(\n",
    "    dictionary=test_dictionary,\n",
    "    categories=categories,\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "target, _ = generator.next()\n",
    "\n",
    "target_bounding_boxes, target_categories, target_images, target_masks, target_metadata = target\n",
    "\n",
    "target_bounding_boxes = numpy.squeeze(target_bounding_boxes)\n",
    "\n",
    "target_images = numpy.squeeze(target_images)\n",
    "\n",
    "target_categories = numpy.argmax(target_categories, -1)\n",
    "\n",
    "target_categories = numpy.squeeze(target_categories)\n",
    "\n",
    "utils.show_bounding_boxes(target_images, target_bounding_boxes, target_categories)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_dictionary[0]['objects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsna",
   "language": "python",
   "name": "rsna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
